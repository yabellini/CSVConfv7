---
title: ""
format:
  revealjs: 
    slide-number: true
    chalkboard: 
      buttons: false
    preview-links: auto
    logo: images/lettering_black.svg
    footer: <https://ropensci.org/>
---

![](images/presentacion.svg)

::: {.notes}
Hello, my name is Yani Bellini Saibene, I made this work with Sandro Camargo, who send cheers from Brasil.
Welcome to "TELL ME WHO YOU HANG OUT WITH, AND I WILL TELL YOU WHO YOU ARE". In Spanish: "Dime con quien andas y te diré quien eres". This is a well-known phrase in Argentina.  It refers to the groups of people we get together with to do things: the swim team, the book club, the knitters, our college friends or the R-Ladies chapter. In this talk we are going to refer to a special kind of group called Community of Practice.
:::

# Communities of Practice

> groups of people who **share a 
passion** for something that they **know 
how to do**, and who **interact regularly** 
in order to **learn how to do it better** -- _Etienne Wenger_

::: {.notes}
Why I'm talking about this? because In June last year, I become community Manager of rOpenSci, a community of practice
:::

## rOpenSci {.smaller}

we are a group of people who passion is __open and reproducible research__ to everyone, buid it by everyone. And we know how to do it by creating __technical and social infrastructure__. 

:::: {.columns}

::: {.column width="60%"}
::: {.incremental}
- Creating a suite of carefully vetted, federated R software tools.
- Making the right data, tools and best practices more discoverable.
- Welcoming and diverse community.
- Building capacity of software users and developers and fostering a sense of pride in their work. 
- Promoting advocacy for a culture of data sharing and reusable software.
:::
:::

::: {.column width="40%"}
![](images/computadora_dos.png) 
:::

::::

::: {.notes}
We do this creating a suite of carefully vetted, federated R software tools. Developers of research software send their package to our review process, and after they pass, the package is part of our suite. Developers get support on from our staff and from the community. Users get high quality software to do science.

Making the right data, tools and best practices more discoverable. Our R-Universe platform allows to publish and search more than 18000 R packages. 

Welcoming and diverse community through a code of conduct, our Champions Program and our multilingual publishing efforts. 

Building capacity of software users and developers and fostering a sense of pride in their work with the projets I already mention, but also by publishing online books, organizing community call and co-working session, higlighing developer with interviews and creating contect on our web pages, forum and newsletter.

:::


## Community Manager

:::: {.columns}

::: {.column width="50%"}
> **Facilitates** the **activities** of a community and the **interactions** between **community members.** 
Community management may be considered as _“in-reach”_ rather than _“outreach”_ or public engagement. - CSCCE

:::

::: {.column width="50%"}
![](images/skills.svg) 
:::

::::





::: footer
Learn more: [What is Community Engagement Within Science?](https://www.cscce.org/about/community-engagement/), [What does a scientific community manager do?](https://www.cscce.org/2021/01/25/what-does-a-scientific-community-manager-do-check-out-the-cscce-skills-wheel-and-accompanying-guidebook/)
:::

::: {.notes}
A community manager in the context of a community of practice is a person that facilitates the activities of a community and the interaction with their members.  Have responsabilities in task in technical, interpersonal, communication, program management and program development aspect.

:::

# Let's analyze rOpenSci community

# Why analyze our community?

![](images/question_dos.png){.r-stretch}

::: {.notes}
essentially because by knowing your community you can do a better job in the role of community manager.

rOpenSci records a lot of data and generates statistics and summaries, for example, how many packages we reviewed, how many blog posts we wrote, how many community calls we organized and how many people came. This are very useful and show us an overal idea of our community and our activities.

:::


## 

Communities are __built on connections__. 

. . .

We need to know our community connectivity to __plan targeted__ and __effective interventions__ to:

::: {.incremental}
- improve collaborations.
- improve information flow.
- improve knowledge reuse.
- effective knowledge (co)creation.
- effective knowledge transfer.
:::


::: {.notes}
Now, communities are built on connections, and those summaries and number don't give us many information about  the growth and strength of professional interpersonal connections in our community. 
:::

## 

### At a given moment in time

::: {.incremental}
- Who is connected to whom? Who is not connected?
- Where, and who, are the __hubs__?
- Where and about what are the __clusters__? Are there __silos__?
:::

### Changes over time

::: {.incremental}
- Are new __connection__ forming?
- Are new __patterns__ of connectivity forming?
- How was our network __before and after__ the introduction of an activity?
:::

::: {.notes}
We will try to answer questions like:
:::

# How we can analyze our community connectivity?

![](images/coneccion_dos.png){.r-stretch}

## Social Networks Analysis

Group of individuals who relate to others for a specific purpose, characterized by the existence of information flows.

![](images/red_1.svg)
::: {.notes}
Here is where Social Networks Analysis comes into play. I'm not talking about twitter or instagram here, I'm talking about networks build by individuals u organization that have some kind of relationship.
:::

## Social Networks Analysis - Basic elements

![](images/red_2.svg){.r-stretch}

---

## Social Networks Analysis - Basic elements

![](images/red_3.svg){.r-stretch}
---

## Social Networks Analysis - Basic elements

![](images/red_4.svg){.r-stretch}


## Social Networks Analysis - Basic elements

![](images/red_full.svg){.r-stretch}

::: {.notes}
You can map the nodes and edges to explore the connections and patterns that exist
and make conclusions based off of that exploration, for example, here we have map network, with the people as nodes and the edges as collaborations, for example, write a blog post together, being co-authors.

:::

## Social Networks Analysis - Basic elements

![](images/red_full_degree.svg){.r-stretch}

::: {.notes}
The degree of a node is how many connection have, for example this node has 6 connection, so the degree is 6.  This other have 5 connections so the degree is 5. higer degree, more connected is the node.

:::


## Social Networks Analysis - Basic elements

![](images/red_full_multiplexity.svg){.r-stretch}

::: {.notes}
The multiplexity show the number of connection between two nodes, for example
you co-author more than one blog post.

:::

## Social Networks Analysis - Basic elements

![](images/red_full_centrality.svg){.r-stretch}

::: {.notes}
Betweenness centrality measures the number of times a node lies on the shortest path between other nodes. What it tells us: This measure shows which nodes are 'bridges' between nodes in a network.

:::

## Social Networks Analysis - Basic elements

![](images/red_full_closeness.svg){.r-stretch}

::: {.notes}
Scores each node based on how close it is to all other nodes in the network.
It is useful for finding the individuals who are best placed to influence the entire network most quickly.
:::


## Social Networks Analysis - Basic elements

![](images/red_full_clusters.svg){.r-stretch}

::: {.notes}
Clusters or communities are groups that work together, their nodes have high number of connection between them. A clique cluster have all thier memebers interconected and a silo don't have connection with other clusters on the network.

:::

# How we can collect the data?

![](images/charlando.png){.r-stretch}

::: {.notes}
For this type of analysis we need data that reveal some kind of connection between the actors in a network.

The most common data collection methods used in social network analysis are surveys and interviews collect from members in the network. As you can imagine, this can be costly in time and money.  

The data also could come from existing data, like data on social
media connections, and it can come from your own knowledge of the relationships that exist in the network.

So we thought, is it possible that we already have that data in another format and we can accommodate it to analyze the connectivity of our community? is it possible that we could collect that data in an automated or semi-automated way to repeat the analysis?

:::

## Path to contribute at rOpenSci {.smaller}

:::: {.columns}

::: {.column width="33%"}
![](images/escribiendo.png){height="180" fig-align="center"}

Write a blog post



![](images/telescopio.png){.fragment height="180" fig-align="center"}

Review a package
:::

::: {.column width="33%"}

![](images/engranajes.png){.fragment height="180" fig-align="center"}

Maintain a package

![](images/hablar.png){.fragment height="180" fig-align="center"}

Speak at a Comm Call 

:::

::: {.column width="33%"}
![](images/champion.png){.fragment height="180" fig-align="center"}

Become a champion

![](images/idea.png){.fragment height="180" fig-align="center"}

Host a coworking session

:::

::::

::: footer
Learn more: [rOpenSci Community Contributing Guide](https://contributing.ropensci.org/) and [How to Participate with rOpenSci](https://ropensci.org/blog/2022/09/13/contributing-ropensci/)
:::

::: {.notes}
Fortunately at rOpenSci we have a contribution guide, there is a whole book describing the different ways you can contribute to the community. For example, you can, Write a blog post, Review a package, Maintain a package, Speak at a Community Call, Become a champion, Host a coworking session. 

Many of these forms of contribution can be made with other people and there we have our nodes and a connection between them.
:::

## How we can represent and measure contributions? {.smaller}

|Node | Edge | Type of contribution | Source |
|-----|------|----------------------|--------|
|Author | coauthorship| blog post, books, talks, interviews| Webpage |


## How we can represent and measure contributions? {.smaller}

|Node | Edge | Type of contribution | Source |
|-----|------|----------------------|--------|
|Author | coauthorship| blog post, books, talks, interviews| Webpage |
|Participant | coorganization, cospeaking, coattendence | community calls, co-working sessions, unconf| Webpage |



## How we can represent and measure contributions? {.smaller}

|Node | Edge | Type of contribution | Source |
|-----|------|----------------------|--------|
|Author | coauthorship| blog post, books, talks, interviews| Webpage |
|Participant | coorganization, cospeaking, coattendence | community calls, co-working sessions, unconf| Webpage |
|Developers, Users | Codevelopment | Suite of packages, r-universe| Github, r-universe |


## How we can represent and measure contributions? {.smaller}

|Node | Edge | Type of contribution | Source |
|-----|------|----------------------|--------|
|Author | coauthorship| blog post, books, talks, interviews| Webpage |
|Participant | coorganization, cospeaking, coattendence | community calls, co-working sessions, unconf| Webpage |
|Developers, Users | Codevelopment | Suite of packages, r-universe| Github, r-universe |
|Author, editor, reviewers |package peer-review|Software & Stat Peer-review|Data base, GitHub |


## How we can represent and measure contributions? {.smaller}

|Node | Edge | Type of contribution | Source |
|-----|------|----------------------|--------|
|Author | coauthorship| blog post, books, talks, interviews| Webpage |
|Participant | coorganization, cospeaking, coattendence | community calls, co-working sessions, unconf| Webpage |
|Developers, Users | Codevelopment | Suite of packages, r-universe| Github, r-universe |
|Author, editor, reviewers |package peer-review|Software & Stat Peer-review|Data base, GitHub |
|Mentor, Mentee | mentoring | champions program, package development| Data base, Webpage|


## Let's see an example with the Blog

![](images/yaml.png){fig-align="center"}

## Let's see an example with the Blog  {.smaller}

```{.r code-line-numbers="|1,2,3,4|6,7,8,9,10|12|13|14,15,16,17,18,19,20|23"}
file_list <- fs::dir_ls(path = "content/blog/", 
                        recurse = TRUE, 
                        type = "file", 
                        glob = "*.md") 

datos <- tibble(fecha = character(), 
                titulo = character(),
                autor = character(), 
                year = character(), 
                contribution_type = character())
                
for (documento in file_list){ 
  doc <- rmarkdown::yaml_front_matter(input = file.path(documento)) 
  datos <- tibble::add_row(datos, 
                           fecha = doc$date, 
                           titulo = doc$title, 
                           autor = doc$author, 
                           year = as.character(year(date(doc$date))), 
                           contribution_type = 'blog post' 
                           )  
}

write_csv(datos, "blog_post_authors_2023.csv") # ;-)                

```
::: {.notes}
1. Read all the files in the `content/blog/` folder with the `.md` extension  
2. Create a tibble with the variables to store: _date, title, author, year_ and _contribution_type_.
3. For each markdown document
4. Read the YAML header, extract the value of each variable
5. and add a row in the dataset with the information
6. After process all the documents, we save the dataset to a CSV file ;-)
:::


## Let's see an example with the Blog

![](images/network.png){height="350" fig-align="center"}

``` {.r code-line-numbers="|1|2|3|4|5"}
results <- blogpost_authors |> 
  group_by(titulo, year) |>
  filter(n() > 1) |> 
  summarise(as.data.frame(t(combn(autor, 2)))) |>
  select(titulo, year, from=V1, to=V2)

```
::: {.notes}
the next step is to transform the list of author of each blog post in a table with network format.

This code take the list we create in the previws step. Group by tile and year and keep all the blog post that have two authors or more.  Then, for each group, the combn function create a matrix with two rows and columns representing all the unique combination of two authors. We transpose this data to get two columns that become _from_ and _to_, epresenting the nodes.

:::


## Blog-Post full network 2013-2023 

![](images/full_blog_post.png){fig-align="center"} 


##  We can analyze it annually 


:::: {.columns}

::: {.column width="50%"}
![](images/blog_post_2014.png){height="500" fig-align="center"}
:::

::: {.column width="50%"}
![](images/blog_post_2022.png){height="500" fig-align="center"}
:::

::::

::: {.notes}
We can also have a network for each year and see how the model changes over time. Now we also add the name of the author to the node.
:::

## We can identify contributors {.smaller}

__Top 10 contributors - Blog Post__

|Name|Contributions|Degree|Centrality|Page Rank|
|----|-----:|-----:|-----:|-----:|
|Scott Chamberlain|		98|	15|	0.03|	0.02|
|Stefanie Butland|		72|	18|	0.04|	0.01|
|Maëlle Salmon|		62	|27|	0.05|	0.03|
|Jeroen Ooms|		60|	6|	0.01|	0.006|
|Karthik Ram|		50|	19|	0.01|	0.03|
|Noam Ross|		29|	33|	0.22|	0.03|
|The rOpenSci Team|		24|	10|	0.001|	0.005|
|Yanina Bellini Saibene|		22|	10|	0.003|	0.01|
|Steffi LaZerte|		19|	15|	0.05|	0.01|
|Mark Padgham|		16|	22|	0.06|	0.01|

## We can identify contributors {.smaller}

__Top 10 contributors - Blog Post - No staff members__

|Name|Contributions|Degree|Centrality|Page Rank|
|----|-----:|-----:|-----:|-----:|
|Kara Woo|		11|	9|	9.09E-4|	0.010195|
|Anna Krystalli|		9|	17|	0.003553|	0.020155|
|Lincoln Mullen|		8|	13|	0.068667|	0.013976|
|Melina Vidoni|		8|	14|	0.002583|	0.018365|
|Brooke Anderson|		7|	20|	0.020534|	0.017369|
|Kelly O'Briant|		7|	1|	0.0|	0.001375|
|Nicholas Tierney|		7|	10|	0.054712|	0.007526|
|Carl Boettiger|		6|	14|	0.067459|	0.009321|
|Hugo Gruson|		6|	12|	0.037093|	0.010062|
|Laura DeCicco|		6|	21|	0.051456|	0.017206|


## We can see all contribution together 

![](images/full_network.png){.r-stretch}

## We can identify contributors {.smaller}

__Top 10 contributors - Full Network__

|Name|Contributions|Degree|Centrality|Page Rank|
|----|-----:|-----:|-----:|-----:|
|Maelle Salmon|	254|	110|	0,12|	0,019|
|Scott Chamberlain|	250|	134|	0,22|	0,022|
|Karthik Ram|	189	|67	|0,06|	0,014|
|Noam Ross|	189	|73	|0,09|	0,013|
|Anna Krystalli|	118|	39	|0,01|	0,008|
|Laura DeCicco|	96|	55	|0,06|	0,007|
|Brooke Anderson|	91|	43|	0,02|0,006|
|Mark Padgham|	89|	53	|0,03|	0,007|
|Melina Vidoni|	85|	21	|0,02|	0,006|
|Mauro Lepore|	74|	35	|0,02|	0,005|


## What's next? 

### SNA can be use for a __descriptive__ and __exploratory__ analysis of your community.


::: {.incremental}
* Complete and go deep with our analysis.
* How can we add other types of contributions?
* The nodes can be organizations, communities, institutions.
* Add direction to the links, to map information flow.
:::


## What if you wanted to do the same for your community?


![](images/leer.png){.r-stretch}


## My tips

::: {.incremental}

* Define the nodes in your network (people, countries, organizations, ...) 
* Define the type(s) of connection you have in your network.
    * Start with your paths for contributions.
    * Identify which contributions can be done in teams.
* Probably you are alredy registering information about those type of connection.

:::

## My tips

::: {.incremental}

* You can automatize a portion of the data collection.
    * Formalize the workflow (code ;-)) so you can repeat & reproduce.
* It is hard to capture all type of interactions.
  * Take into account open/close/privacy of the data. 
* Knowing the nodes help to undertand the clusters and the interactions.
  * Lean on the people who have been in the network for the longest time.

:::

## My tips

::: {.incremental}

* You can take snapshot of the network model ... 
* ... so you can compare it at different times.
* ... so you can use it for evaluating the impact of interventions and programs.
* Share what you find with your community
* ... and other community managers.

:::


## ¡Gracias, Thank you, Obrigada!{.smaller}

:::: {.columns}

::: {.column width="60%"}
- Slides: 
- Code: 
- The pictures are adaptation by my 7yo son and me to [images by Freepik](https://www.freepik.com/free-vector/hand-drawn-colorful-stickman-collection_20884529.htm) on [hand drawn style stickman set](https://www.freepik.com/free-vector/hand-drawn-style-stickman-set_20884532.htm)
- We use R, gephy, excalidraw and quarto for build this talk.
- Thanks to the rOpenSci Staff Team, Elio and Ale for their feedback.
:::

::: {.column width="40%"}
![](images/hi-five.png)
:::

::::






